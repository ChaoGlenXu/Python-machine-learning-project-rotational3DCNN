{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aps360_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpjmJp6RN_Ef"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKntRsA2N6lw"
      },
      "source": [
        "# example data\n",
        "# Batch x Height x Width x Length x Label\n",
        "data = [[[[0, 0],[0, 0]],[[0, 1],[1, 1]]], [[[1, 1],[0, 1]],[[0, 0],[1, 1]]]]\n",
        "data_tensor = torch.FloatTensor(data)\n",
        "label = [[[[1, 0],[0, 1]],[[0, 1],[1, 1]]], [[[0, 1],[1, 0]],[[1, 1],[1, 1]]]]\n",
        "label_tensor = torch.FloatTensor(label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOq260CVUEWX",
        "outputId": "7c49e44d-cf7f-4122-f8ef-d8fdcc0d1a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, args):\n",
        "\n",
        "        # acquire configuration file\n",
        "        config = get_config(args.config)\n",
        "        self.config = config\n",
        "\n",
        "        # setup saving operations\n",
        "        iters, losses, train_acc, val_acc = [], [], [], []\n",
        "        model_instance_list =[]\n",
        "\n",
        "        # load model (pre-trained or saved) - have a model configuration\n",
        "        self.model = get_model(config)\n",
        "\n",
        "        # load datasets - create dataloaders (use config file)\n",
        "        self.dataset = ShapeNet(config)\n",
        "\n",
        "\n",
        "        # setup metric global metric structures (loss, metric classes)\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "        # loop over epochs\n",
        "        for self.epoch in self.config['num_epochs']:\n",
        "            self.run_epoch()\n",
        "            self.save()\n",
        "\n",
        "            iters.append(self.epoch)\n",
        "        self.save_metrics()\n",
        "        return 0\n",
        "\n",
        "    def run_epoch(self):\n",
        "\n",
        "        # run a training epoch #!!!: need to add another loop for each sample in the epoch\n",
        "        for data, labels in self.config['num_epochs']:\n",
        "          out = self.model(data_tensor)\n",
        "          loss = criterion(out, labels) # compute the loss\n",
        "          loss.backward()               # obtain gradients\n",
        "          optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "          # track metrics\n",
        "          losses.append(float(loss)/self.epoch)   # compute average loss\n",
        "          train_acc.append(get_accuracy(data_tensor, label_tensor)) # compute training accuracy\n",
        "          \n",
        "\n",
        "          # model.eval()\n",
        "          # run an evaluation epoch\n",
        "        \n",
        "              # track metrics\n",
        "\n",
        "    def get_metrics(self, preds, labels):\n",
        "        # compute desired metrics for batch and return\n",
        "        return get_iou_per_batch(self, preds, labels) \n",
        "\n",
        "    def save(self):\n",
        "        # save current model instance \n",
        "        return model_instance_list.append(self.model(data_tensor))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # parse CLI inputs\n",
        "    parser = argparse.ArgumentParser(description='Training Configuration')\n",
        "    parser.add_argument('--config', required=True, help='Path to configuration file')\n",
        "    parser.add_argument('--continue', type=bool, default=False, help=\"Continue training a previous model\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # create trainer and start training\n",
        "    trainer = Trainer(args)\n",
        "    trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8ddaaacc545c>\"\u001b[0;36m, line \u001b[0;32m70\u001b[0m\n\u001b[0;31m    def get_metrics(self, preds, labels):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    }
  ]
}