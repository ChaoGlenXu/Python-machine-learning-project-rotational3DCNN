# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-dca76oiUod-kdahKdMscUlKh7RxWbwX
"""

import os
import argparse
import torch
import torch.nn as nn
import torch.functional as F
from torch.utils.data import DataLoader

import pandas as pd
import numpy as np


import csv
import random
import torch.utils.data
import matplotlib.pyplot as plt

# example data
# Batch x Height x Width x Length x Label
data = [[[[0, 0],[0, 0]],[[0, 1],[1, 1]]], [[[1, 1],[0, 1]],[[0, 0],[1, 1]]]]
data_tensor = torch.FloatTensor(data)
label = [[[[1, 0],[0, 1]],[[0, 1],[1, 1]]], [[[0, 1],[1, 0]],[[1, 1],[1, 1]]]]
label_tensor = torch.FloatTensor(label)

class Trainer:

    def __init__(self, args):

        # acquire configuration file
        config = get_config(args.config)
        self.config = config

        # setup saving operations
        iters, losses, train_acc, val_acc = [], [], [], []
        model_instance_list =[]

        # load model (pre-trained or saved) - have a model configuration
        self.model = get_model(config)

        # load datasets - create dataloaders (use config file)
        self.dataset = ShapeNet(config)


        # setup metric global metric structures (loss, metric classes)
        self.criterion = nn.BCEWithLogitsLoss()


    def train(self):
        self.epoch = 0

        # loop over epochs
        for self.epoch in self.config['num_epochs']:
            self.run_epoch()
            self.save()

            iters.append(self.epoch)
        self.save_metrics()
        return 0

    def run_epoch(self):

        # run a training epoch #!!!: need to add another loop for each sample in the epoch
        for data, labels in self.config['num_epochs']:
          out = self.model(data_tensor)
          loss = criterion(out, labels) # compute the loss
          loss.backward()               # obtain gradients
          optimizer.zero_grad()         # a clean up step for PyTorch
          # track metrics
          losses.append(float(loss)/self.epoch)   # compute average loss
          train_acc.append(get_accuracy(data_tensor, label_tensor)) # compute training accuracy
          

          # model.eval()
          # run an evaluation epoch
        
              # track metrics

    def get_metrics(self, preds, labels):
        # compute desired metrics for batch and return
        return get_iou_per_batch(self, preds, labels) 

    def save(self):
        # save current model instance 
        return model_instance_list.append(self.model(data_tensor))


if __name__ == '__main__':
    # parse CLI inputs
    parser = argparse.ArgumentParser(description='Training Configuration')
    parser.add_argument('--config', required=True, help='Path to configuration file')
    parser.add_argument('--continue', type=bool, default=False, help="Continue training a previous model")
    args = parser.parse_args()

    # create trainer and start training
    trainer = Trainer(args)
    trainer.train()